#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Ü–∏–∫–ª –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –≥–æ–¥ –≤ –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ—Ç –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –≥–æ–¥
"""

import pandas as pd
import numpy as np
import pickle
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import RobustScaler
from sklearn.neighbors import KNeighborsRegressor
from sklearn.pipeline import Pipeline
import warnings
warnings.filterwarnings('ignore')

def load_model():
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏–∑ –ø—É–Ω–∫—Ç–∞ 18"""
    try:
        with open('knn_full_components.pkl', 'rb') as f:
            model_components = pickle.load(f)
        
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {model_components['model_name']}")
        print(f"–ü—Ä–∏–∑–Ω–∞–∫–∏ –º–æ–¥–µ–ª–∏: {model_components['selected_features']}")
        return model_components
    
    except FileNotFoundError:
        print("‚ùå –§–∞–π–ª –º–æ–¥–µ–ª–∏ 'knn_full_components.pkl' –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return None

def load_data_and_detect_year(file_path):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥–æ–¥–∞"""
    try:
        data = pd.read_excel(file_path)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–æ–¥—ã –≤ –¥–∞–Ω–Ω—ã—Ö
        years_in_data = sorted(data['Year'].unique()) if 'Year' in data.columns else []
        
        if not years_in_data:
            # –ï—Å–ª–∏ Year –Ω–µ—Ç, –ø—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∏–∑ –¥–∞—Ç
            date_col = data.columns[0]
            if 'Unnamed' not in date_col:
                dates = pd.to_datetime(data[date_col])
                years_in_data = sorted(dates.dt.year.unique())
        
        start_year = min(years_in_data) if years_in_data else None
        end_year = max(years_in_data) if years_in_data else None
        
        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(data)} —Å—Ç—Ä–æ–∫, {len(data.columns)} —Å—Ç–æ–ª–±—Ü–æ–≤")
        print(f"üìÖ –ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö: {start_year} - {end_year}")
        
        return data, start_year, end_year
    
    except Exception as e:
        raise ValueError(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")

def process_date_column(data):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç–æ–ª–±—Ü–∞ —Å –¥–∞—Ç–æ–π - —Å–æ–∑–¥–∞–Ω–∏–µ Year –∏ Month"""
    print("\nüìÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞—Ç—ã...")
    
    date_col = data.columns[0]  # –ü–µ—Ä–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü
    
    try:
        if pd.api.types.is_datetime64_any_dtype(data[date_col]):
            dates = data[date_col]
        else:
            dates = pd.to_datetime(data[date_col])
        
        data['Year'] = dates.dt.year
        data['–ú–µ—Å—è—Ü'] = dates.dt.month
        
        years = sorted(data['Year'].unique())
        months = sorted(data['–ú–µ—Å—è—Ü'].unique())
        
        print(f"   ‚úÖ –ì–æ–¥—ã: {years}")
        print(f"   ‚úÖ –ú–µ—Å—è—Ü—ã: {months}")
        print(f"   ‚úÖ –ü–µ—Ä–∏–æ–¥: {dates.min().strftime('%Y-%m')} –¥–æ {dates.max().strftime('%Y-%m')}")
        
        return data, date_col, years[0], years[-1]
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞—Ç—ã: {e}")
        raise ValueError(f"–ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–∞—Ç—É –≤ —Å—Ç–æ–ª–±—Ü–µ '{date_col}'")

def find_column_mapping(data, target_columns):
    """–ü–æ–∏—Å–∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤"""
    print("\nüîç –ü–æ–∏—Å–∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤...")
    
    mapping = {}
    available_cols = data.columns.tolist()
    
    for target in target_columns:
        print(f"\nüîç –ò—â–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¥–ª—è '{target}':")
        
        # –ü—Ä—è–º–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if target in data.columns:
            mapping[target] = target
            print(f"   ‚úÖ –ü—Ä—è–º–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: {target}")
            continue
        
        # –ü–æ–∏—Å–∫ –ø–æ —á–∞—Å—Ç–∏—á–Ω–æ–º—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é
        best_match = None
        best_score = 0
        
        for col in available_cols:
            score = 0
            col_clean = col.lower().replace('\xa0', ' ').replace('-', ' ').replace('_', ' ')
            target_clean = target.lower().replace('_', ' ')
            
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            if '–æ—Ñ—Ñ–∑' in target.lower() and ('–æ—Ñ–∑' in col_clean or '–¥–æ—Ö–æ–¥–Ω' in col_clean):
                score += 3
            elif '–∏–ø—Ü' in target.lower() and ('–∏–ø—Ü' in col_clean or '—Ü–µ–Ω' in col_clean):
                score += 3
            elif '–∑–ø' in target.lower() and ('–∑–ø' in col_clean or '–∑–∞—Ä–ø–ª–∞—Ç' in col_clean):
                score += 3
            elif target_clean in col_clean:
                score += 2
            
            if score > best_score:
                best_score = score
                best_match = col
        
        if best_match and best_score > 0:
            mapping[target] = best_match
            print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ: '{best_match}' (—Å—á—ë—Ç: {best_score})")
        else:
            print(f"   ‚ùå –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            mapping[target] = None
    
    return mapping

def create_full_features(data, target_col):
    """–°–æ–∑–¥–∞–Ω–∏–µ –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∫–∞–∫ –≤ –æ–±—É—á–∞—é—â–µ–º –ø–∞–π–ø–ª–∞–π–Ω–µ"""
    print("\nüîß –°–æ–∑–¥–∞–Ω–∏–µ –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    
    # 1. –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    data['–ú–µ—Å—è—Ü_sin'] = np.sin(2 * np.pi * (data['–ú–µ—Å—è—Ü'] - 1) / 12)
    data['–ú–µ—Å—è—Ü_cos'] = np.cos(2 * np.pi * (data['–ú–µ—Å—è—Ü'] - 1) / 12)
    data['–ö–≤–∞—Ä—Ç–∞–ª'] = (data['–ú–µ—Å—è—Ü'] - 1) // 3 + 1
    print(f"   ‚úÖ –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å–æ–∑–¥–∞–Ω—ã")
    
    # 2. –õ–∞–≥–∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    data[f'{target_col}_lag_1'] = data[target_col].shift(1)
    data['target_lag_1'] = data[target_col].shift(1)
    print(f"   ‚úÖ –õ–∞–≥–∏ —Å–æ–∑–¥–∞–Ω—ã: {target_col}_lag_1, target_lag_1")
    
    # 3. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –¥–ª—è –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    feature_mapping = {
        '–î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å_–û–§–ó': None,
        '–ò–ü–¶': None, 
        '–ó–ü': None
    }
    
    # –ù–∞—Ö–æ–¥–∏–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    for required, _ in feature_mapping.items():
        for col in data.columns:
            if required.replace('_', '').lower() in col.lower().replace(' ', '').replace('_', ''):
                feature_mapping[required] = col
                break
    
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ —Å–ø–∏—Å–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    main_features = ['–ú–µ—Å—è—Ü_sin', '–ú–µ—Å—è—Ü_cos', '–ö–≤–∞—Ä—Ç–∞–ª']
    for req_feature, actual_feature in feature_mapping.items():
        if actual_feature:
            main_features.append(actual_feature)
            print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–∏–∑–Ω–∞–∫: {req_feature} -> {actual_feature}")
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
    for feature in main_features:
        if feature in data.columns:
            # MA3
            data[f'{feature}_MA3'] = data[feature].rolling(window=3, min_periods=1).mean()
            # std3
            data[f'{feature}_std3'] = data[feature].rolling(window=3, min_periods=1).std().fillna(0)
            print(f"   ‚úÖ –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –¥–ª—è {feature}")
    
    return data

def universal_forecast_workflow(file_path="2016_year_data.xlsx"):
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Ü–∏–∫–ª –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –≥–æ–¥–∞"""
    print("üöÄ –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô –¶–ò–ö–õ –ü–†–û–ì–ù–û–ó–ò–†–û–í–ê–ù–ò–Ø")
    print("=" * 60)
    
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    model_components = load_model()
    if not model_components:
        return None
    
    # 2. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥–æ–¥–∞
    data, start_year, end_year = load_data_and_detect_year(file_path)
    
    # 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞—Ç—ã
    data, date_col, data_start_year, data_end_year = process_date_column(data)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–æ–¥ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞
    forecast_year = data_end_year + 1
    print(f"\nüéØ –ó–ê–î–ê–ß–ê: –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ {forecast_year} –≥–æ–¥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö –∑–∞ {data_start_year}-{data_end_year}")
    
    # 4. –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    target_col = '–ü—Ä–∏—Ä–æ—Å—Ç –≤–∫–ª–∞–¥–æ–≤ —Ñ–∏–∑–∏—á–µ—Å–∫–∏—Ö –ª–∏—Ü –≤ —Ä—É–±–ª—è—Ö (–º–ª–Ω —Ä—É–±)'
    data = create_full_features(data, target_col)
    
    # 5. –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–∞—Ç–µ
    data = data.sort_values(['Year', '–ú–µ—Å—è—Ü']).reset_index(drop=True)
    
    # 6. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    print(f"\nüéØ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏...")
    
    # –ù–∞—Ö–æ–¥–∏–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    feature_mapping = find_column_mapping(data, model_components['selected_features'])
    
    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã
    rename_mapping = {v: k for k, v in feature_mapping.items() if k != v}
    if rename_mapping:
        data = data.rename(columns=rename_mapping)
        print(f"üìù –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ:")
        for old, new in rename_mapping.items():
            print(f"   {old} -> {new}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
    missing_features = [f for f in model_components['selected_features'] if f not in data.columns]
    if missing_features:
        print(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏: {missing_features}")
        return None
    
    print(f"‚úÖ –í—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –º–æ–¥–µ–ª–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã!")
    
    # 7. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ X –∏ y
    X = data[model_components['selected_features']]
    y = data[target_col]
    
    print(f"üìä –î–∞–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–∏: {X.shape}, y: {len(y)}")
    
    # 8. –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å k=3
    pipeline = Pipeline([
        ('imputer', SimpleImputer(strategy='median')),
        ('scaler', RobustScaler()),
        ('model', KNeighborsRegressor(n_neighbors=3, p=2))
    ])
    
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    pipeline.fit(X, y)
    print(f"‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ —Å k=3")
    
    # 9. –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –≥–æ–¥
    print(f"\nüîÑ –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ {forecast_year} –≥–æ–¥...")
    
    # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 12 —Å—Ç—Ä–æ–∫ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞
    X_last_12 = X.tail(12)
    
    # –î–µ–ª–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑
    forecast = pipeline.predict(X_last_12)
    
    # 10. –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    forecast_dates = pd.date_range(start=f'{forecast_year}-01-01', periods=12, freq='MS')
    
    print(f"\nüìÖ –ü–†–û–ì–ù–û–ó –ù–ê {forecast_year} –ì–û–î (–º–æ–¥–µ–ª—å k=3)")
    print("=" * 70)
    
    for i, (date, value) in enumerate(zip(forecast_dates, forecast)):
        month = i + 1
        print(f"   {forecast_year}-{month:02d}: {value:>12,.2f} –º–ª–Ω —Ä—É–±")
    
    # 11. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞
    unique_values = len(np.unique(np.round(forecast, 2)))
    print(f"\nüìä –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–≥–Ω–æ–∑–∞:")
    print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {unique_values}")
    if unique_values > 2:
        print(f"   ‚úÖ –ü—Ä–æ–≥–Ω–æ–∑ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–π!")
    else:
        print(f"   ‚ùå –ü—Ä–æ–≥–Ω–æ–∑ —Å–ª–∏—à–∫–æ–º –æ–¥–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–π")
    
    # 12. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    final_forecast = pd.Series(forecast, index=forecast_dates)
    filename_csv = f"forecast_{forecast_year}_k3_universal.csv"
    filename_xlsx = f"forecast_{forecast_year}_k3_universal.xlsx"
    
    final_forecast.to_csv(filename_csv, header=['–ü—Ä–æ–≥–Ω–æ–∑'])
    final_forecast.to_excel(filename_xlsx, header=['–ü—Ä–æ–≥–Ω–æ–∑'])
    
    print(f"\nüíæ –ü—Ä–æ–≥–Ω–æ–∑ —Å–æ—Ö—Ä–∞–Ω—ë–Ω:")
    print(f"   - {filename_csv}")
    print(f"   - {filename_xlsx}")
    
    return final_forecast

if __name__ == "__main__":
    try:
        # –ú–æ–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–∞–Ω–Ω—ã—Ö
        data_file = "2016_year_data.xlsx"  # –ò–∑–º–µ–Ω–∏—Ç—å –Ω–∞ –Ω—É–∂–Ω—ã–π —Ñ–∞–π–ª
        final_forecast = universal_forecast_workflow(data_file)
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()

def process_uploaded_file(file_path):
    """–û–±–µ—Ä—Ç–∫–∞ –¥–ª—è –≤—ã–∑–æ–≤–∞ –∏–∑ Flask"""
    try:
        # –ü—Ä–æ—Å—Ç–æ –≤—ã–∑—ã–≤–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Ñ—É–Ω–∫—Ü–∏—é
        final_forecast = universal_forecast_workflow(file_path)
        
        if final_forecast is None:
            return None, "–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞"
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≥–æ–¥ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞
        forecast_year = final_forecast.index[0].year
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è Flask
        results = {
            'forecast_year': forecast_year,
            'data_period': "—Å–º. –ª–æ–≥–∏",  # –≠—Ç–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –≤—ã–≤–æ–¥–∏—Ç—Å—è –≤ –∫–æ–Ω—Å–æ–ª—å
            'forecast_values': [(f"{forecast_year}-{i+1:02d}", float(value)) 
                              for i, value in enumerate(final_forecast.values)],
            'filename_csv': f"forecast_{forecast_year}_k3_universal.csv",
            'filename_xlsx': f"forecast_{forecast_year}_k3_universal.xlsx",
            'unique_values': len(np.unique(np.round(final_forecast.values, 2)))
        }
        
        return results, None
        
    except Exception as e:
        return None, str(e)